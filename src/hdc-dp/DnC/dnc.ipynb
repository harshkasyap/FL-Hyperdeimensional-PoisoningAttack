{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a189859",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio, copy, os, socket, sys, time\n",
    "from functools import partial\n",
    "from multiprocessing import Pool, Process\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "from libs import agg, data, fl, hdc, helper, log, nn, plot, poison, resnet, sim, wandb\n",
    "from cfgs.fedargs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7e0cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkasyah\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/kasyah/fl-poison/runs/1qysj5li\" target=\"_blank\">fedavg-cnn-mnist-hdc-dp</a></strong> to <a href=\"https://wandb.ai/kasyah/fl-poison\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project = 'fl-poison'\n",
    "name = 'fedavg-cnn-mnist-hdc-dp'\n",
    "\n",
    "# Save Logs To File (info | debug | warning | error | critical) [optional]\n",
    "log.init(\"info\")\n",
    "#log.init(\"info\", name)\n",
    "#log.init(\"debug\", name)\n",
    "\n",
    "cosine_attack[\"is\"] = True\n",
    "FLTrust[\"is\"] = True\n",
    "\n",
    "fedargs.agg_rule = agg.Rule.DnC\n",
    "fedargs.tb = SummaryWriter('../out/runs/' + project + '/' + name, comment=\"fl\")\n",
    "wb = wandb.init(name, project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb399c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device settings\n",
    "use_cuda = fedargs.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(fedargs.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76542fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare clients\n",
    "host = socket.gethostname()\n",
    "clients = [host + \"(\" + str(client + 1) + \")\" for client in range(fedargs.num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402306c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Global and Client models\n",
    "global_model = copy.deepcopy(fedargs.model)\n",
    "# Load Data to clients\n",
    "train_data, test_data = data.load_dataset(fedargs.dataset, only_to_tensor = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca573ed",
   "metadata": {},
   "source": [
    "<h2>FLTrust</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe42e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLTrust[\"is\"]:\n",
    "    train_data, FLTrust[\"data\"] = data.random_split(train_data, FLTrust[\"ratio\"])\n",
    "    FLTrust[\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "    if FLTrust[\"proxy\"][\"is\"]:\n",
    "        FLTrust[\"data\"], FLTrust[\"proxy\"][\"data\"] = data.random_split(FLTrust[\"data\"], FLTrust[\"proxy\"][\"ratio\"])\n",
    "        FLTrust[\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)\n",
    "        FLTrust[\"proxy\"][\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"proxy\"][\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025440b",
   "metadata": {},
   "source": [
    "<h2>Prepare a backdoored loader for test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "769acb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backdoor_attack[\"is\"]:\n",
    "    train_data, backdoor_attack[\"data\"] = data.random_split(train_data, backdoor_attack[\"ratio\"])\n",
    "    backdoor_attack[\"data\"] = poison.insert_trojan(backdoor_attack[\"data\"],\n",
    "                                                   backdoor_attack[\"target_label\"],\n",
    "                                                   backdoor_attack[\"trojan_func\"], 1)\n",
    "    backdoor_attack[\"loader\"] = torch.utils.data.DataLoader(backdoor_attack[\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f568d4",
   "metadata": {},
   "source": [
    "<h2>Load client's data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80508740",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_data = data.split_data(train_data, clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e1723a",
   "metadata": {},
   "source": [
    "<h2>HDC DP Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "885276ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def hdc_train(hdc_data, device, hdc_args):\n",
    "    hdc_data_loader = torch.utils.data.DataLoader(hdc_data, batch_size=len(hdc_data), shuffle=True)\n",
    "    hdc_model = hdc.HDC(hdc_args[\"one_d_len\"], hdc_args[\"hdc_proj_len\"], len(hdc_args[\"labels\"]), device)\n",
    "    train_acc = hdc_model.train(hdc_data_loader, device)\n",
    "    return hdc_model\n",
    "\n",
    "if hdc_dp_attack[\"is\"]:\n",
    "    hdc_tasks = [hdc_train(clients_data[clients[client]], device,\n",
    "                            hdc_dp_attack[\"args\"]) for client in mal_clients]\n",
    "    try:\n",
    "        hdc_models = fedargs.loop.run_until_complete(asyncio.gather(*hdc_tasks))\n",
    "    except KeyboardInterrupt as e:\n",
    "        log.error(\"Caught keyboard interrupt. Canceling hdc_dps...\")\n",
    "        hdc_tasks.cancel()\n",
    "        fedargs.loop.run_forever()\n",
    "        hdc_tasks.exception()\n",
    "\n",
    "    hdc_clients_data = {client: (clients_data[clients[client]], hdc_models[index])\n",
    "                        for index, client in enumerate(mal_clients)}\n",
    "\n",
    "    mal_clients_data = hdc_dp_attack[\"func\"](hdc_clients_data,\n",
    "                                             hdc_dp_attack[\"args\"],\n",
    "                                             label_flip_attack[\"labels\"],\n",
    "                                             hdc_dp_attack[\"percent\"])\n",
    "\n",
    "    for client, mal_data in enumerate(mal_clients_data):\n",
    "        clients_data[clients[client]] = mal_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670c19d",
   "metadata": {},
   "source": [
    "<h2>Label Flip Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43985c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if label_flip_attack[\"is\"]:\n",
    "    for client in mal_clients:\n",
    "        clients_data[clients[client]] = label_flip_attack[\"func\"](clients_data[clients[client]],\n",
    "                                                                  label_flip_attack[\"labels\"],\n",
    "                                                                  label_flip_attack[\"percent\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01394f",
   "metadata": {},
   "source": [
    "<h2>Backdoor Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11198f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backdoor_attack[\"is\"]:\n",
    "    for client in mal_clients:\n",
    "        clients_data[clients[client]] = poison.insert_trojan(clients_data[clients[client]],\n",
    "                                                             backdoor_attack[\"target_label\"],\n",
    "                                                             backdoor_attack[\"trojan_func\"], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f21c1481",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_train_loaders, _ = data.load_client_data(clients_data, fedargs.client_batch_size, None, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=fedargs.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "client_details = {\n",
    "        client: {\"train_loader\": client_train_loaders[client],\n",
    "                 \"model\": copy.deepcopy(global_model),\n",
    "                 \"model_update\": None}\n",
    "        for client in clients\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af4f472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def process(client, epoch, model, train_loader, fedargs, device):\n",
    "    # Train\n",
    "    model_update, model, loss = fedargs.train_func(model, train_loader, \n",
    "                                                   fedargs.learning_rate,\n",
    "                                                   fedargs.weight_decay,\n",
    "                                                   fedargs.local_rounds, device)\n",
    "\n",
    "    log.jsondebug(loss, \"Epoch {} of {} : Federated Training loss, Client {}\".format(epoch, fedargs.epochs, client))\n",
    "    log.modeldebug(model_update, \"Epoch {} of {} : Client {} Update\".format(epoch, fedargs.epochs, client))\n",
    "    \n",
    "    return model_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7f3fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51 [00:00<?, ?it/s]2022-01-12 15:27:40,815 - <ipython-input-14-ff08476993c1>::<module>(l:6) : Federated Training Epoch 0 of 51 [MainProcess : MainThread (INFO)]\n",
      "  2%|▏         | 1/51 [02:02<1:41:58, 122.37s/it]2022-01-12 15:29:42,859 - <ipython-input-14-ff08476993c1>::<module>(l:6) : Federated Training Epoch 1 of 51 [MainProcess : MainThread (INFO)]\n",
      "2022-01-12 15:30:14,832 - <ipython-input-14-ff08476993c1>::<module>(l:24) : Global Test Outut after Epoch 1 of 51 {\n",
      "    \"accuracy\": 63.519999999999996,\n",
      "    \"correct\": 6352,\n",
      "    \"test_loss\": 2.1990076740264892\n",
      "} [MainProcess : MainThread (INFO)]\n",
      "  4%|▍         | 2/51 [04:35<1:54:29, 140.20s/it]2022-01-12 15:32:15,536 - <ipython-input-14-ff08476993c1>::<module>(l:6) : Federated Training Epoch 2 of 51 [MainProcess : MainThread (INFO)]\n",
      "2022-01-12 15:32:48,707 - <ipython-input-14-ff08476993c1>::<module>(l:24) : Global Test Outut after Epoch 2 of 51 {\n",
      "    \"accuracy\": 76.51,\n",
      "    \"correct\": 7651,\n",
      "    \"test_loss\": 1.9288776399612426\n",
      "} [MainProcess : MainThread (INFO)]\n",
      "  6%|▌         | 3/51 [07:07<1:56:29, 145.61s/it]2022-01-12 15:34:47,586 - <ipython-input-14-ff08476993c1>::<module>(l:6) : Federated Training Epoch 3 of 51 [MainProcess : MainThread (INFO)]\n",
      "2022-01-12 15:35:19,676 - <ipython-input-14-ff08476993c1>::<module>(l:24) : Global Test Outut after Epoch 3 of 51 {\n",
      "    \"accuracy\": 79.67999999999999,\n",
      "    \"correct\": 7968,\n",
      "    \"test_loss\": 1.5995968809127807\n",
      "} [MainProcess : MainThread (INFO)]\n",
      "  8%|▊         | 4/51 [09:40<1:56:24, 148.61s/it]2022-01-12 15:37:20,781 - <ipython-input-14-ff08476993c1>::<module>(l:6) : Federated Training Epoch 4 of 51 [MainProcess : MainThread (INFO)]\n",
      "2022-01-12 15:37:52,635 - <ipython-input-14-ff08476993c1>::<module>(l:24) : Global Test Outut after Epoch 4 of 51 {\n",
      "    \"accuracy\": 82.07,\n",
      "    \"correct\": 8207,\n",
      "    \"test_loss\": 1.2722659748077392\n",
      "} [MainProcess : MainThread (INFO)]\n",
      " 10%|▉         | 5/51 [12:11<1:54:33, 149.42s/it]2022-01-12 15:39:51,646 - <ipython-input-14-ff08476993c1>::<module>(l:6) : Federated Training Epoch 5 of 51 [MainProcess : MainThread (INFO)]\n",
      "2022-01-12 15:40:24,189 - <ipython-input-14-ff08476993c1>::<module>(l:24) : Global Test Outut after Epoch 5 of 51 {\n",
      "    \"accuracy\": 83.1,\n",
      "    \"correct\": 8310,\n",
      "    \"test_loss\": 1.0092447462081908\n",
      "} [MainProcess : MainThread (INFO)]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "    \n",
    "# Federated Training\n",
    "for epoch in tqdm(range(fedargs.epochs)):\n",
    "    log.info(\"Federated Training Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "\n",
    "    # Global Model Update\n",
    "    if epoch > 0:\n",
    "        # For Tmean and FLTrust, not impacts others as of now\n",
    "        avgargs = {\"beta\": len(mal_clients), \n",
    "                   \"base_model_update\": global_model_update if FLTrust[\"is\"] else None,\n",
    "                   \"base_norm\": True}\n",
    "        \n",
    "        # Average\n",
    "        global_model = fl.federated_avg(client_model_updates, global_model, fedargs.agg_rule, **avgargs)\n",
    "        log.modeldebug(global_model, \"Epoch {}: Server Update\".format(epoch))\n",
    "        \n",
    "        # Test, Plot and Log\n",
    "        global_test_output = fedargs.eval_func(global_model, test_loader, device, label_flip_attack[\"labels\"])\n",
    "        fedargs.tb.add_scalar(\"Gloabl Accuracy/\", global_test_output[\"accuracy\"], epoch)\n",
    "        fedargs.tb.add_scalar(\"Global Test Loss/\", global_test_output[\"test_loss\"], epoch)\n",
    "        wb.log({\"epoch\": epoch, \"time\": time.time(), \"acc\": global_test_output[\"accuracy\"], \"loss\": global_test_output[\"test_loss\"]})\n",
    "        log.jsoninfo(global_test_output, \"Global Test Outut after Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "        \n",
    "        # Evaluate LFA\n",
    "        if \"attack\" in global_test_output:\n",
    "            if \"attack_success_rate\" in global_test_output[\"attack\"]:\n",
    "                wb.log({\"attack_success_rate\": global_test_output[\"attack\"][\"attack_success_rate\"]})\n",
    "                fedargs.tb.add_scalar(\"Attack Success Rate/\", global_test_output[\"attack\"][\"attack_success_rate\"], epoch)\n",
    "            if \"misclassification_rate\" in global_test_output[\"attack\"]:\n",
    "                wb.log({\"misclassification_rate\": global_test_output[\"attack\"][\"misclassification_rate\"]})\n",
    "                fedargs.tb.add_scalar(\"Misclassification Rate/\", global_test_output[\"attack\"][\"misclassification_rate\"], epoch)\n",
    "\n",
    "        # Evaluate Backdoor\n",
    "        if backdoor_attack[\"is\"]:\n",
    "            backdoor_test_output = fl.backdoor_test(global_model, backdoor_attack[\"loader\"], device, backdoor_attack[\"target_label\"])\n",
    "            fedargs.tb.add_scalar(\"Backdoor Success Rate/\", backdoor_test_output[\"accuracy\"], epoch)\n",
    "            wb.log({\"backdoor_success_rate\": backdoor_test_output[\"accuracy\"]})\n",
    "            log.jsoninfo(backdoor_test_output, \"Backdoor Test Outut after Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "\n",
    "        # Update client models\n",
    "        for client in clients:\n",
    "            client_details[client]['model'] = copy.deepcopy(global_model)\n",
    "\n",
    "    # Clients\n",
    "    tasks = [process(client, epoch, client_details[client]['model'],\n",
    "                     client_details[client]['train_loader'],\n",
    "                     fedargs, device) for client in clients]\n",
    "    try:\n",
    "        updates = fedargs.loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    except KeyboardInterrupt as e:\n",
    "        log.error(\"Caught keyboard interrupt. Canceling tasks...\")\n",
    "        tasks.cancel()\n",
    "        fedargs.loop.run_forever()\n",
    "        tasks.exception()\n",
    "\n",
    "    for client, update in zip(clients, updates):\n",
    "        client_details[client]['model_update'] = update\n",
    "    client_model_updates = {client: details[\"model_update\"] for client, details in client_details.items()}\n",
    "    \n",
    "    # Fang attack\n",
    "    if fang_attack[\"is\"]:\n",
    "        client_model_updates = fang_attack[\"func\"](client_model_updates, len(mal_clients), fang_attack[\"kn\"])\n",
    "        \n",
    "    # LIE attack\n",
    "    if lie_attack[\"is\"]:\n",
    "        client_model_updates = lie_attack[\"func\"](client_model_updates, len(mal_clients), lie_attack[\"kn\"])\n",
    "   \n",
    "    # SOTA attack\n",
    "    if sota_attack[\"is\"]:\n",
    "        client_model_updates = sota_attack[\"func\"](client_model_updates, len(mal_clients), \n",
    "                                                   sota_attack[\"kn\"], sota_attack[\"dev_type\"])\n",
    "    \n",
    "    # FLtrust or FLTC based aggregation rules or attacks\n",
    "    if FLTrust[\"is\"]:\n",
    "        global_model_update, _, _ = fedargs.train_func(global_model, FLTrust[\"loader\"],\n",
    "                                                       fedargs.learning_rate,\n",
    "                                                       fedargs.weight_decay,\n",
    "                                                       fedargs.local_rounds, device)\n",
    "\n",
    "        # For Attacks related to FLTrust\n",
    "        base_model_update = global_model_update\n",
    "        if FLTrust[\"proxy\"][\"is\"]:\n",
    "            base_model_update, _, _ = fedargs.train_func(global_model, FLTrust[\"proxy\"][\"loader\"],\n",
    "                                                         fedargs.learning_rate,\n",
    "                                                         fedargs.weight_decay,\n",
    "                                                         fedargs.local_rounds, device)\n",
    "        \n",
    "        # Layer replacement attack\n",
    "        if layer_replacement_attack[\"is\"]:\n",
    "            for client in mal_clients:\n",
    "                client_details[clients[client]]['model_update'] = layer_replacement_attack[\"func\"](base_model_update,\n",
    "                                                                                                   client_details[clients[client]]['model_update'],\n",
    "                                                                                                   layer_replacement_attack[\"layers\"])\n",
    "\n",
    "        # For cosine attack, Malicious Clients\n",
    "        if cosine_attack[\"is\"]:\n",
    "            p_models, params_changed = cosine_attack[\"func\"](base_model_update, cosine_attack[\"args\"], epoch,\n",
    "                                                             client_model_updates, len(mal_clients), cosine_attack[\"kn\"])\n",
    "            \n",
    "            for client, p_model in enumerate(p_models):\n",
    "                client_details[clients[client]]['model_update'] = p_model \n",
    "\n",
    "            #plot params changed for only one client\n",
    "            fedargs.tb.add_scalar(\"Params Changed for Cosine Attack/\", params_changed, epoch)\n",
    "\n",
    "        # For sybil attack, Malicious Clients\n",
    "        if sybil_attack[\"is\"]:\n",
    "            for client in mal_clients:\n",
    "                client_details[clients[client]]['model_update'] = base_model_update\n",
    "                \n",
    "        # again pair, as changed during attack\n",
    "        client_model_updates = {client: details[\"model_update\"] for client, details in client_details.items()}\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b2d6a9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<h1> End </h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:syft]",
   "language": "python",
   "name": "conda-env-syft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
