{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "sys.path.insert(0,'./../utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from cifar10_normal_train import *\n",
    "from cifar10_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adam import Adam\n",
    "from sgd import SGD\n",
    "from gradient_aggregation_rules import *\n",
    "from poisoning_attacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "data_loc='/mnt/nfs/work1/amir/vshejwalkar/cifar10_data/'\n",
    "# load the train dataset\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(root=data_loc, train=True, download=True, transform=train_transform)\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(root=data_loc, train=False, download=True, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data len:  60000\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "for i in range(len(cifar10_train)):\n",
    "    X.append(cifar10_train[i][0].numpy())\n",
    "    Y.append(cifar10_train[i][1])\n",
    "\n",
    "for i in range(len(cifar10_test)):\n",
    "    X.append(cifar10_test[i][0].numpy())\n",
    "    Y.append(cifar10_test[i][1])\n",
    "\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "\n",
    "print('total data len: ',len(X))\n",
    "\n",
    "if not os.path.isfile('./cifar10_shuffle.pkl'):\n",
    "    all_indices = np.arange(len(X))\n",
    "    np.random.shuffle(all_indices)\n",
    "    pickle.dump(all_indices,open('./cifar10_shuffle.pkl','wb'))\n",
    "else:\n",
    "    all_indices=pickle.load(open('./cifar10_shuffle.pkl','rb'))\n",
    "\n",
    "X=X[all_indices]\n",
    "Y=Y[all_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data len:  60000\n",
      "total tr len 50000 | val len 5000 | test len 5000\n",
      "user 0 tr len 1000\n",
      "user 1 tr len 1000\n",
      "user 2 tr len 1000\n",
      "user 3 tr len 1000\n",
      "user 4 tr len 1000\n",
      "user 5 tr len 1000\n",
      "user 6 tr len 1000\n",
      "user 7 tr len 1000\n",
      "user 8 tr len 1000\n",
      "user 9 tr len 1000\n",
      "user 10 tr len 1000\n",
      "user 11 tr len 1000\n",
      "user 12 tr len 1000\n",
      "user 13 tr len 1000\n",
      "user 14 tr len 1000\n",
      "user 15 tr len 1000\n",
      "user 16 tr len 1000\n",
      "user 17 tr len 1000\n",
      "user 18 tr len 1000\n",
      "user 19 tr len 1000\n",
      "user 20 tr len 1000\n",
      "user 21 tr len 1000\n",
      "user 22 tr len 1000\n",
      "user 23 tr len 1000\n",
      "user 24 tr len 1000\n",
      "user 25 tr len 1000\n",
      "user 26 tr len 1000\n",
      "user 27 tr len 1000\n",
      "user 28 tr len 1000\n",
      "user 29 tr len 1000\n",
      "user 30 tr len 1000\n",
      "user 31 tr len 1000\n",
      "user 32 tr len 1000\n",
      "user 33 tr len 1000\n",
      "user 34 tr len 1000\n",
      "user 35 tr len 1000\n",
      "user 36 tr len 1000\n",
      "user 37 tr len 1000\n",
      "user 38 tr len 1000\n",
      "user 39 tr len 1000\n",
      "user 40 tr len 1000\n",
      "user 41 tr len 1000\n",
      "user 42 tr len 1000\n",
      "user 43 tr len 1000\n",
      "user 44 tr len 1000\n",
      "user 45 tr len 1000\n",
      "user 46 tr len 1000\n",
      "user 47 tr len 1000\n",
      "user 48 tr len 1000\n",
      "user 49 tr len 1000\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "\n",
    "nusers=50\n",
    "user_tr_len=1000\n",
    "\n",
    "total_tr_len=user_tr_len*nusers\n",
    "val_len=5000\n",
    "te_len=5000\n",
    "\n",
    "print('total data len: ',len(X))\n",
    "\n",
    "if not os.path.isfile('./cifar10_shuffle.pkl'):\n",
    "    all_indices = np.arange(len(X))\n",
    "    np.random.shuffle(all_indices)\n",
    "    pickle.dump(all_indices,open('./cifar10_shuffle.pkl','wb'))\n",
    "else:\n",
    "    all_indices=pickle.load(open('./cifar10_shuffle.pkl','rb'))\n",
    "\n",
    "total_tr_data=X[:total_tr_len]\n",
    "total_tr_label=Y[:total_tr_len]\n",
    "\n",
    "val_data=X[total_tr_len:(total_tr_len+val_len)]\n",
    "val_label=Y[total_tr_len:(total_tr_len+val_len)]\n",
    "\n",
    "te_data=X[(total_tr_len+val_len):(total_tr_len+val_len+te_len)]\n",
    "te_label=Y[(total_tr_len+val_len):(total_tr_len+val_len+te_len)]\n",
    "\n",
    "total_tr_data_tensor=torch.from_numpy(total_tr_data).type(torch.FloatTensor)\n",
    "total_tr_label_tensor=torch.from_numpy(total_tr_label).type(torch.LongTensor)\n",
    "\n",
    "val_data_tensor=torch.from_numpy(val_data).type(torch.FloatTensor)\n",
    "val_label_tensor=torch.from_numpy(val_label).type(torch.LongTensor)\n",
    "\n",
    "te_data_tensor=torch.from_numpy(te_data).type(torch.FloatTensor)\n",
    "te_label_tensor=torch.from_numpy(te_label).type(torch.LongTensor)\n",
    "\n",
    "print('total tr len %d | val len %d | test len %d'%(len(total_tr_data_tensor),len(val_data_tensor),len(te_data_tensor)))\n",
    "\n",
    "#==============================================================================================================\n",
    "\n",
    "user_tr_data_tensors=[]\n",
    "user_tr_label_tensors=[]\n",
    "\n",
    "for i in range(nusers):\n",
    "    \n",
    "    user_tr_data_tensor=torch.from_numpy(total_tr_data[user_tr_len*i:user_tr_len*(i+1)]).type(torch.FloatTensor)\n",
    "    user_tr_label_tensor=torch.from_numpy(total_tr_label[user_tr_len*i:user_tr_len*(i+1)]).type(torch.LongTensor)\n",
    "\n",
    "    user_tr_data_tensors.append(user_tr_data_tensor)\n",
    "    user_tr_label_tensors.append(user_tr_label_tensor)\n",
    "    print('user %d tr len %d'%(i,len(user_tr_data_tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lie_attack(all_updates, z):\n",
    "    avg = torch.mean(all_updates, dim=0)\n",
    "    std = torch.std(all_updates, dim=0)\n",
    "    return avg + z * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnc(all_updates, n_attackers, num_buckets=1, bucket=100000):\n",
    "    n, d = all_updates.shape\n",
    "    \n",
    "    final_indices = []\n",
    "    \n",
    "    for p in np.arange(num_buckets):\n",
    "        idx = np.sort(np.random.choice(d, bucket, replace=False))\n",
    "        sampled_all_updates = all_updates[:, idx]\n",
    "        sampled_good_updates = all_updates[n_attackers:][:, idx]\n",
    "\n",
    "        centered_all_updates = sampled_all_updates - torch.mean(sampled_all_updates, 0)\n",
    "        centered_good_updates = sampled_good_updates - torch.mean(sampled_good_updates, 0)\n",
    "        \n",
    "        u, s, v = torch.svd(centered_all_updates)\n",
    "        u_g, s_g, v_g = torch.svd(centered_good_updates)\n",
    "        \n",
    "        scores = torch.mm(centered_all_updates, v[:,0][:, None]).cpu().numpy()\n",
    "        \n",
    "        final_indices.append(list(np.argsort(scores[:,0]**2)[:(n-int(1.5*n_attackers))]))\n",
    "\n",
    "    result = set(final_indices[0]) \n",
    "    for currSet in final_indices[1:]: \n",
    "        result.intersection_update(currSet)\n",
    "    final_idx = np.array(list(result))\n",
    "    # print(np.array(final_idx), len((final_idx)))\n",
    "    \n",
    "    return torch.mean(all_updates[final_idx], 0), final_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious_grads shape is  torch.Size([50, 2472266])\n",
      "bulyan: at lie n_at 10 z 0.73 e 0 fed_model val loss 2.3031 val acc 12.7435 best val_acc 12.743506 te_acc 12.297078\n",
      "bulyan: at lie n_at 10 z 0.73 e 10 fed_model val loss 2.2984 val acc 15.7873 best val_acc 15.990260 te_acc 16.761364\n",
      "bulyan: at lie n_at 10 z 0.73 e 20 fed_model val loss 2.2824 val acc 22.1997 best val_acc 22.199675 te_acc 20.921266\n",
      "bulyan: at lie n_at 10 z 0.73 e 30 fed_model val loss 2.2231 val acc 18.5471 best val_acc 22.199675 te_acc 20.921266\n",
      "bulyan: at lie n_at 10 z 0.73 e 40 fed_model val loss 2.2184 val acc 14.4075 best val_acc 22.463474 te_acc 22.260552\n",
      "number of malicious grads chosen are  [[10 10 10 10 10 10 10  0 10  5]\n",
      " [10  8 10 10 10 10 10 10 10  6]\n",
      " [10 10 10 10 10 10 10 10 10 10]\n",
      " [10  9 10  8  8 10 10 10 10 10]\n",
      " [10 10 10  7 10 10 10 10 10 10]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 50 fed_model val loss 2.1084 val acc 22.4635 best val_acc 25.426136 te_acc 23.863636\n",
      "bulyan: at lie n_at 10 z 0.73 e 60 fed_model val loss 2.0757 val acc 22.9505 best val_acc 25.426136 te_acc 23.863636\n",
      "bulyan: at lie n_at 10 z 0.73 e 70 fed_model val loss 2.1840 val acc 18.8312 best val_acc 25.710227 te_acc 24.046266\n",
      "bulyan: at lie n_at 10 z 0.73 e 80 fed_model val loss 2.1576 val acc 15.3206 best val_acc 26.176948 te_acc 25.669643\n",
      "bulyan: at lie n_at 10 z 0.73 e 90 fed_model val loss 2.0521 val acc 22.2403 best val_acc 26.176948 te_acc 25.669643\n",
      "number of malicious grads chosen are  [[10 10 10 10 10 10 10 10 10  9]\n",
      " [10 10  7  7  6  7  2 10 10  9]\n",
      " [10 10 10  2  3 10  8 10 10  8]\n",
      " [10 10 10  2 10  9  4 10 10 10]\n",
      " [10  3 10  8 10  8 10  9 10 10]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 100 fed_model val loss 2.0525 val acc 23.4578 best val_acc 26.826299 te_acc 26.542208\n",
      "bulyan: at lie n_at 10 z 0.73 e 110 fed_model val loss 2.0025 val acc 26.3596 best val_acc 26.826299 te_acc 26.542208\n",
      "bulyan: at lie n_at 10 z 0.73 e 120 fed_model val loss 1.9116 val acc 25.2435 best val_acc 29.646916 te_acc 28.104708\n",
      "bulyan: at lie n_at 10 z 0.73 e 130 fed_model val loss 1.8945 val acc 28.9367 best val_acc 30.296266 te_acc 29.849838\n",
      "bulyan: at lie n_at 10 z 0.73 e 140 fed_model val loss 1.9036 val acc 30.9862 best val_acc 30.986201 te_acc 30.133929\n",
      "number of malicious grads chosen are  [[ 9  8 10 10 10 10 10  2 10 10]\n",
      " [ 8 10  5  6  7 10 10  8  3 10]\n",
      " [10  6 10  4  3 10 10  3 10 10]\n",
      " [ 7  3  0  6 10 10 10  8  5  7]\n",
      " [ 4 10  3 10 10  4  3  1 10  0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 150 fed_model val loss 1.8928 val acc 28.2265 best val_acc 33.786526 te_acc 33.563312\n",
      "bulyan: at lie n_at 10 z 0.73 e 160 fed_model val loss 1.9566 val acc 28.4497 best val_acc 34.740260 te_acc 35.531656\n",
      "bulyan: at lie n_at 10 z 0.73 e 170 fed_model val loss 1.8411 val acc 32.2037 best val_acc 34.740260 te_acc 35.531656\n",
      "bulyan: at lie n_at 10 z 0.73 e 180 fed_model val loss 2.1491 val acc 24.3506 best val_acc 36.059253 te_acc 36.241883\n",
      "bulyan: at lie n_at 10 z 0.73 e 190 fed_model val loss 1.9111 val acc 30.4383 best val_acc 37.885552 te_acc 37.276786\n",
      "number of malicious grads chosen are  [[ 2  0  1  4  0  4  2  8  0  9]\n",
      " [10  0  4  3 10 10  5  0  6  4]\n",
      " [ 5  9  3  2  8  5 10  0  5  4]\n",
      " [ 2  2  3 10  1  2 10 10  0  4]\n",
      " [ 9 10  4  3  5  0  5  4  0  1]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 200 fed_model val loss 1.7009 val acc 37.3377 best val_acc 37.885552 te_acc 37.276786\n",
      "bulyan: at lie n_at 10 z 0.73 e 210 fed_model val loss 1.7550 val acc 34.2735 best val_acc 37.885552 te_acc 37.276786\n",
      "bulyan: at lie n_at 10 z 0.73 e 220 fed_model val loss 1.7034 val acc 36.4042 best val_acc 39.508929 te_acc 39.346591\n",
      "bulyan: at lie n_at 10 z 0.73 e 230 fed_model val loss 1.7964 val acc 33.3198 best val_acc 39.508929 te_acc 39.346591\n",
      "bulyan: at lie n_at 10 z 0.73 e 240 fed_model val loss 1.6837 val acc 38.7784 best val_acc 39.752435 te_acc 39.366883\n",
      "number of malicious grads chosen are  [[ 0  0  1  5  1  0  0  4  5  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0]\n",
      " [ 3  0  0  0  4  0 10  3  0  0]\n",
      " [ 0 10  9  0  0  0  1  0  1  0]\n",
      " [ 3  0  0  1  0  5  0  0  0  2]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 250 fed_model val loss 1.8644 val acc 30.1948 best val_acc 39.752435 te_acc 39.366883\n",
      "bulyan: at lie n_at 10 z 0.73 e 260 fed_model val loss 1.7008 val acc 38.9813 best val_acc 40.219156 te_acc 39.549513\n",
      "bulyan: at lie n_at 10 z 0.73 e 270 fed_model val loss 1.6514 val acc 39.7119 best val_acc 41.964286 te_acc 42.674513\n",
      "bulyan: at lie n_at 10 z 0.73 e 280 fed_model val loss 1.6774 val acc 40.4221 best val_acc 42.370130 te_acc 42.025162\n",
      "bulyan: at lie n_at 10 z 0.73 e 290 fed_model val loss 1.5745 val acc 42.5933 best val_acc 43.607955 te_acc 43.689123\n",
      "number of malicious grads chosen are  [[ 3  0  0 10  0  0  7  0  7  0]\n",
      " [ 0  0  0  2  1  0  0  0  7  0]\n",
      " [10  0  0  0  0  0  0  0  2  1]\n",
      " [ 0  0  0  0  0  0  1  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 300 fed_model val loss 1.5982 val acc 39.8336 best val_acc 44.845779 te_acc 44.906656\n",
      "bulyan: at lie n_at 10 z 0.73 e 310 fed_model val loss 1.5963 val acc 39.6916 best val_acc 45.109578 te_acc 45.170455\n",
      "bulyan: at lie n_at 10 z 0.73 e 320 fed_model val loss 1.5485 val acc 44.2979 best val_acc 46.854708 te_acc 46.428571\n",
      "bulyan: at lie n_at 10 z 0.73 e 330 fed_model val loss 1.4604 val acc 46.6518 best val_acc 47.382305 te_acc 47.504058\n",
      "bulyan: at lie n_at 10 z 0.73 e 340 fed_model val loss 1.5756 val acc 42.8166 best val_acc 47.382305 te_acc 47.504058\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 7 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 350 fed_model val loss 1.5027 val acc 44.6023 best val_acc 47.382305 te_acc 47.504058\n",
      "bulyan: at lie n_at 10 z 0.73 e 360 fed_model val loss 1.5149 val acc 46.0430 best val_acc 47.544643 te_acc 47.219968\n",
      "bulyan: at lie n_at 10 z 0.73 e 370 fed_model val loss 1.4231 val acc 47.9099 best val_acc 48.173701 te_acc 48.315747\n",
      "bulyan: at lie n_at 10 z 0.73 e 380 fed_model val loss 1.6133 val acc 43.1818 best val_acc 48.173701 te_acc 48.315747\n",
      "bulyan: at lie n_at 10 z 0.73 e 390 fed_model val loss 1.6183 val acc 40.8076 best val_acc 49.594156 te_acc 50.811688\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 400 fed_model val loss 1.6605 val acc 39.3466 best val_acc 49.594156 te_acc 50.811688\n",
      "bulyan: at lie n_at 10 z 0.73 e 410 fed_model val loss 1.5471 val acc 44.0341 best val_acc 49.594156 te_acc 50.811688\n",
      "bulyan: at lie n_at 10 z 0.73 e 420 fed_model val loss 1.3821 val acc 50.1623 best val_acc 50.162338 te_acc 51.521916\n",
      "bulyan: at lie n_at 10 z 0.73 e 430 fed_model val loss 1.5199 val acc 47.0779 best val_acc 50.162338 te_acc 51.521916\n",
      "bulyan: at lie n_at 10 z 0.73 e 440 fed_model val loss 1.4890 val acc 43.8515 best val_acc 50.162338 te_acc 51.521916\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 450 fed_model val loss 1.4621 val acc 46.4489 best val_acc 50.892857 te_acc 51.176948\n",
      "bulyan: at lie n_at 10 z 0.73 e 460 fed_model val loss 1.4275 val acc 48.7622 best val_acc 50.892857 te_acc 51.176948\n",
      "bulyan: at lie n_at 10 z 0.73 e 470 fed_model val loss 1.4519 val acc 47.8084 best val_acc 50.892857 te_acc 51.176948\n",
      "bulyan: at lie n_at 10 z 0.73 e 480 fed_model val loss 1.3348 val acc 52.0495 best val_acc 52.049513 te_acc 52.272727\n",
      "bulyan: at lie n_at 10 z 0.73 e 490 fed_model val loss 1.3480 val acc 51.1567 best val_acc 53.693182 te_acc 54.910714\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 500 fed_model val loss 1.3785 val acc 50.8523 best val_acc 53.693182 te_acc 54.910714\n",
      "bulyan: at lie n_at 10 z 0.73 e 510 fed_model val loss 1.3930 val acc 50.0812 best val_acc 53.693182 te_acc 54.910714\n",
      "bulyan: at lie n_at 10 z 0.73 e 520 fed_model val loss 1.4414 val acc 48.0114 best val_acc 53.693182 te_acc 54.910714\n",
      "bulyan: at lie n_at 10 z 0.73 e 530 fed_model val loss 1.4408 val acc 46.9765 best val_acc 53.693182 te_acc 54.910714\n",
      "bulyan: at lie n_at 10 z 0.73 e 540 fed_model val loss 1.3214 val acc 53.3076 best val_acc 53.977273 te_acc 54.525162\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 550 fed_model val loss 1.3026 val acc 52.9830 best val_acc 53.977273 te_acc 54.525162\n",
      "bulyan: at lie n_at 10 z 0.73 e 560 fed_model val loss 1.3195 val acc 53.1656 best val_acc 54.910714 te_acc 55.336851\n",
      "bulyan: at lie n_at 10 z 0.73 e 570 fed_model val loss 1.4206 val acc 49.7159 best val_acc 54.910714 te_acc 55.336851\n",
      "bulyan: at lie n_at 10 z 0.73 e 580 fed_model val loss 1.3201 val acc 53.4497 best val_acc 54.910714 te_acc 55.336851\n",
      "bulyan: at lie n_at 10 z 0.73 e 590 fed_model val loss 1.3919 val acc 50.9537 best val_acc 56.412338 te_acc 57.061688\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 600 fed_model val loss 1.3619 val acc 49.4115 best val_acc 56.412338 te_acc 57.061688\n",
      "bulyan: at lie n_at 10 z 0.73 e 610 fed_model val loss 1.4561 val acc 48.2955 best val_acc 56.412338 te_acc 57.061688\n",
      "bulyan: at lie n_at 10 z 0.73 e 620 fed_model val loss 1.3873 val acc 50.7102 best val_acc 56.412338 te_acc 57.061688\n",
      "bulyan: at lie n_at 10 z 0.73 e 630 fed_model val loss 1.3285 val acc 51.7248 best val_acc 56.412338 te_acc 57.061688\n",
      "bulyan: at lie n_at 10 z 0.73 e 640 fed_model val loss 1.4063 val acc 50.1218 best val_acc 56.412338 te_acc 57.061688\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 650 fed_model val loss 1.2698 val acc 55.1339 best val_acc 56.412338 te_acc 57.061688\n",
      "bulyan: at lie n_at 10 z 0.73 e 660 fed_model val loss 1.3460 val acc 53.4091 best val_acc 56.716721 te_acc 58.360390\n",
      "bulyan: at lie n_at 10 z 0.73 e 670 fed_model val loss 1.2559 val acc 55.3774 best val_acc 56.716721 te_acc 58.360390\n",
      "bulyan: at lie n_at 10 z 0.73 e 680 fed_model val loss 1.3870 val acc 49.4115 best val_acc 57.873377 te_acc 57.954545\n",
      "bulyan: at lie n_at 10 z 0.73 e 690 fed_model val loss 1.3274 val acc 53.8149 best val_acc 57.873377 te_acc 57.954545\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 700 fed_model val loss 1.1841 val acc 57.7922 best val_acc 57.873377 te_acc 57.954545\n",
      "bulyan: at lie n_at 10 z 0.73 e 710 fed_model val loss 1.4102 val acc 53.6323 best val_acc 58.157468 te_acc 58.258929\n",
      "bulyan: at lie n_at 10 z 0.73 e 720 fed_model val loss 1.3612 val acc 52.8612 best val_acc 58.157468 te_acc 58.258929\n",
      "bulyan: at lie n_at 10 z 0.73 e 730 fed_model val loss 1.2276 val acc 55.9862 best val_acc 58.157468 te_acc 58.258929\n",
      "bulyan: at lie n_at 10 z 0.73 e 740 fed_model val loss 1.2600 val acc 55.9456 best val_acc 58.157468 te_acc 58.258929\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 750 fed_model val loss 1.3255 val acc 54.3628 best val_acc 58.157468 te_acc 58.258929\n",
      "bulyan: at lie n_at 10 z 0.73 e 760 fed_model val loss 1.4688 val acc 51.5219 best val_acc 58.847403 te_acc 58.867695\n",
      "bulyan: at lie n_at 10 z 0.73 e 770 fed_model val loss 1.3038 val acc 55.2151 best val_acc 58.847403 te_acc 58.867695\n",
      "bulyan: at lie n_at 10 z 0.73 e 780 fed_model val loss 1.2684 val acc 57.0820 best val_acc 60.267857 te_acc 61.120130\n",
      "bulyan: at lie n_at 10 z 0.73 e 790 fed_model val loss 1.3602 val acc 51.7451 best val_acc 60.267857 te_acc 61.120130\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 800 fed_model val loss 1.2139 val acc 56.8588 best val_acc 60.267857 te_acc 61.120130\n",
      "bulyan: at lie n_at 10 z 0.73 e 810 fed_model val loss 1.2357 val acc 57.1226 best val_acc 60.267857 te_acc 61.120130\n",
      "bulyan: at lie n_at 10 z 0.73 e 820 fed_model val loss 1.4786 val acc 49.6956 best val_acc 60.267857 te_acc 61.120130\n",
      "bulyan: at lie n_at 10 z 0.73 e 830 fed_model val loss 1.2691 val acc 57.0414 best val_acc 60.267857 te_acc 61.120130\n",
      "bulyan: at lie n_at 10 z 0.73 e 840 fed_model val loss 1.2817 val acc 55.3571 best val_acc 60.267857 te_acc 61.120130\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 850 fed_model val loss 1.3218 val acc 55.8442 best val_acc 60.267857 te_acc 61.120130\n",
      "bulyan: at lie n_at 10 z 0.73 e 860 fed_model val loss 1.1793 val acc 59.5779 best val_acc 60.267857 te_acc 61.120130\n",
      "bulyan: at lie n_at 10 z 0.73 e 870 fed_model val loss 1.3989 val acc 53.4700 best val_acc 60.267857 te_acc 61.120130\n",
      "bulyan: at lie n_at 10 z 0.73 e 880 fed_model val loss 1.2173 val acc 58.6039 best val_acc 60.267857 te_acc 61.120130\n",
      "bulyan: at lie n_at 10 z 0.73 e 890 fed_model val loss 1.4342 val acc 51.8466 best val_acc 60.267857 te_acc 61.120130\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 900 fed_model val loss 1.2720 val acc 57.0211 best val_acc 60.267857 te_acc 61.120130\n",
      "bulyan: at lie n_at 10 z 0.73 e 910 fed_model val loss 1.2613 val acc 57.7313 best val_acc 60.267857 te_acc 61.120130\n",
      "bulyan: at lie n_at 10 z 0.73 e 920 fed_model val loss 1.3301 val acc 56.1282 best val_acc 60.369318 te_acc 60.612825\n",
      "bulyan: at lie n_at 10 z 0.73 e 930 fed_model val loss 1.2207 val acc 58.3604 best val_acc 60.369318 te_acc 60.612825\n",
      "bulyan: at lie n_at 10 z 0.73 e 940 fed_model val loss 1.4143 val acc 55.5195 best val_acc 60.815747 te_acc 60.004058\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 950 fed_model val loss 1.4808 val acc 51.0755 best val_acc 60.815747 te_acc 60.004058\n",
      "bulyan: at lie n_at 10 z 0.73 e 960 fed_model val loss 1.2190 val acc 58.8880 best val_acc 60.815747 te_acc 60.004058\n",
      "bulyan: at lie n_at 10 z 0.73 e 970 fed_model val loss 1.2927 val acc 59.1721 best val_acc 61.769481 te_acc 61.607143\n",
      "bulyan: at lie n_at 10 z 0.73 e 980 fed_model val loss 1.1735 val acc 60.7549 best val_acc 61.769481 te_acc 61.607143\n",
      "bulyan: at lie n_at 10 z 0.73 e 990 fed_model val loss 1.2823 val acc 59.2735 best val_acc 61.769481 te_acc 61.607143\n",
      "New learnin rate  0.25\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 1000 fed_model val loss 1.1704 val acc 60.0244 best val_acc 61.769481 te_acc 61.607143\n",
      "bulyan: at lie n_at 10 z 0.73 e 1010 fed_model val loss 1.1380 val acc 63.8596 best val_acc 63.961039 te_acc 64.590097\n",
      "bulyan: at lie n_at 10 z 0.73 e 1020 fed_model val loss 1.1772 val acc 64.0016 best val_acc 64.204545 te_acc 64.468344\n",
      "bulyan: at lie n_at 10 z 0.73 e 1030 fed_model val loss 1.2122 val acc 63.7987 best val_acc 64.427760 te_acc 64.894481\n",
      "bulyan: at lie n_at 10 z 0.73 e 1040 fed_model val loss 1.2406 val acc 63.5755 best val_acc 64.427760 te_acc 64.894481\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 1050 fed_model val loss 1.2954 val acc 63.3117 best val_acc 64.427760 te_acc 64.894481\n",
      "bulyan: at lie n_at 10 z 0.73 e 1060 fed_model val loss 1.3212 val acc 63.1494 best val_acc 64.427760 te_acc 64.894481\n",
      "bulyan: at lie n_at 10 z 0.73 e 1070 fed_model val loss 1.3531 val acc 62.8044 best val_acc 64.427760 te_acc 64.894481\n",
      "bulyan: at lie n_at 10 z 0.73 e 1080 fed_model val loss 1.3266 val acc 64.0016 best val_acc 64.427760 te_acc 64.894481\n",
      "bulyan: at lie n_at 10 z 0.73 e 1090 fed_model val loss 1.3878 val acc 63.1899 best val_acc 64.427760 te_acc 64.894481\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 1100 fed_model val loss 1.4268 val acc 63.0276 best val_acc 64.427760 te_acc 64.894481\n",
      "bulyan: at lie n_at 10 z 0.73 e 1110 fed_model val loss 1.4767 val acc 62.9464 best val_acc 64.427760 te_acc 64.894481\n",
      "bulyan: at lie n_at 10 z 0.73 e 1120 fed_model val loss 1.3949 val acc 62.5406 best val_acc 64.427760 te_acc 64.894481\n",
      "bulyan: at lie n_at 10 z 0.73 e 1130 fed_model val loss 1.4291 val acc 63.2914 best val_acc 64.427760 te_acc 64.894481\n",
      "bulyan: at lie n_at 10 z 0.73 e 1140 fed_model val loss 1.4481 val acc 63.2914 best val_acc 64.427760 te_acc 64.894481\n",
      "number of malicious grads chosen are  [[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "bulyan: at lie n_at 10 z 0.73 e 1150 fed_model val loss 1.4796 val acc 63.0276 best val_acc 64.610390 te_acc 64.326299\n",
      "bulyan: at lie n_at 10 z 0.73 e 1160 fed_model val loss 1.6136 val acc 61.8912 best val_acc 64.610390 te_acc 64.326299\n",
      "bulyan: at lie n_at 10 z 0.73 e 1170 fed_model val loss 1.5402 val acc 62.3985 best val_acc 64.610390 te_acc 64.326299\n",
      "bulyan: at lie n_at 10 z 0.73 e 1180 fed_model val loss 1.5326 val acc 64.0219 best val_acc 64.610390 te_acc 64.326299\n",
      "bulyan: at lie n_at 10 z 0.73 e 1190 fed_model val loss 1.6027 val acc 64.0422 best val_acc 64.610390 te_acc 64.326299\n",
      "number of malicious grads chosen are  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "bulyan: at lie n_at 10 z 0.73 e 1199 fed_model val loss 1.6617 val acc 61.3028 best val_acc 64.610390 te_acc 64.326299\n",
      "number of malicious grads chosen are  [0]\n",
      "bulyan: at lie n_at 10 z 0.73 e 1200 fed_model val loss 1.6148 val acc 62.6015 best val_acc 64.610390 te_acc 64.326299\n"
     ]
    }
   ],
   "source": [
    "batch_size=250\n",
    "resume=0\n",
    "nepochs=1200\n",
    "schedule=[1000]\n",
    "nbatches = user_tr_len//batch_size\n",
    "\n",
    "gamma=.5\n",
    "opt = 'sgd'\n",
    "fed_lr=0.5\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "aggregation='dnc'\n",
    "\n",
    "at_type='lie'\n",
    "dev_type = 'std'\n",
    "\n",
    "partial = False\n",
    "z_values={3:0.69847, 5:0.7054, 8:0.71904, 10:0.72575, 12:0.73891}\n",
    "n_attackers=[10]\n",
    "\n",
    "arch='alexnet'\n",
    "chkpt='./'+aggregation\n",
    "\n",
    "bucket_size = 10000\n",
    "num_buckets = 2\n",
    "\n",
    "for n_attacker in n_attackers:\n",
    "    candidates = []\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    torch.cuda.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    epoch_num = 0\n",
    "    best_global_acc = 0\n",
    "    best_global_te_acc = 0\n",
    "\n",
    "    if partial:\n",
    "        fed_file='partial_chkpt_%s_af_%d.pth.tar' % (at_type, n_attacker)\n",
    "        fed_best_file='partial_best_%s_af_%d.pth.tar' % (at_type, n_attacker)\n",
    "    else:\n",
    "        fed_file='chkpt_%s_af_%d.pth.tar' % (at_type, n_attacker)\n",
    "        fed_best_file='best_%s_af_%d.pth.tar' % (at_type, n_attacker)\n",
    "\n",
    "    fed_model, _ = return_model(arch, 0.1, 0.9, parallel=False)\n",
    "    optimizer_fed = SGD(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    if resume:\n",
    "        fed_checkpoint = chkpt+'/'+fed_file\n",
    "        assert os.path.isfile(fed_checkpoint), 'Error: no user checkpoint at %s'%(fed_checkpoint)\n",
    "        checkpoint = torch.load(fed_checkpoint, map_location='cuda:%d'%torch.cuda.current_device())\n",
    "        fed_model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer_fed.load_state_dict(checkpoint['optimizer'])\n",
    "        resume = 0\n",
    "        best_global_acc=checkpoint['best_acc']\n",
    "        best_global_te_acc=checkpoint['best_te_acc']\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        epoch_num += checkpoint['epoch']\n",
    "        print('resuming from epoch %d | val acc %.4f | best acc %.3f | best te acc %.3f'%(epoch_num, val_acc, best_global_acc, best_global_te_acc))\n",
    "\n",
    "    r=np.arange(user_tr_len)\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads=[]\n",
    "        if not epoch_num and epoch_num%nbatches == 0:\n",
    "            np.random.shuffle(r)\n",
    "            for i in range(nusers):\n",
    "                user_tr_data_tensors[i]=user_tr_data_tensors[i][r]\n",
    "                user_tr_label_tensors[i]=user_tr_label_tensors[i][r]\n",
    "\n",
    "        for i in range(nusers):\n",
    "\n",
    "            inputs = user_tr_data_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "            targets = user_tr_label_tensors[i][(epoch_num%nbatches)*batch_size:((epoch_num%nbatches) + 1) * batch_size]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            fed_model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None, :] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]), 0)\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            if at_type == 'lie':\n",
    "                if partial:\n",
    "                    mal_update = lie_attack(user_grads[:n_attacker], z_values[n_attacker])\n",
    "                else:\n",
    "                    mal_update = lie_attack(user_grads, z_values[n_attacker])\n",
    "            elif at_type == 'fang':\n",
    "                if aggregation == 'trmean' or aggregation == 'median':\n",
    "                    if partial:\n",
    "                        mal_update = fang_attack_trmean_partial(malicious_grads, n_attacker)\n",
    "                    else:\n",
    "                        mal_update = fang_attack_trmean(malicious_grads, n_attacker)\n",
    "                else:\n",
    "                    mal_update = fang_attack_krum(malicious_grads, n_attacker)\n",
    "            elif at_type == 'our_agr':\n",
    "                if aggregation == 'krum':\n",
    "                    mal_update = our_attack_krum(malicious_grads, n_attacker, dev_type, threshold=2.0, threshold_diff=1e-7)\n",
    "                elif aggregation == 'mkrum' or aggregation == 'bulyan':\n",
    "                    mal_update = our_attack_mkrum(malicious_grads, n_attacker, dev_type, threshold=2.0, threshold_diff=1e-7)\n",
    "                elif aggregation == 'trmean':\n",
    "                    mal_update = our_attack_trmean(malicious_grads, n_attacker, dev_type, threshold=50.0, threshold_diff=1e-2)\n",
    "                elif aggregation == 'median':\n",
    "                    mal_update = our_attack_median(malicious_grads, n_attacker, dev_type, threshold=50.0, threshold_diff=1e-2)\n",
    "            elif at_type == 'our_noagr_dist':\n",
    "                mal_update = our_attack_dist(malicious_grads, n_attacker, dev_type, threshold_diff = 1e-5)\n",
    "            elif at_type == 'our_noagr_score':\n",
    "                mal_update = our_attack_score(malicious_grads, n_attacker, dev_type, threshold_diff = 1e-5)\n",
    "            \n",
    "            if at_type == 'fang' and (aggregation == 'trmean' or aggregation == 'median'):\n",
    "                mal_updates = mal_update\n",
    "            else:\n",
    "                mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "                \n",
    "            malicious_grads = torch.cat((mal_updates, user_grads[n_attacker:]), 0)\n",
    "            \n",
    "        if epoch_num == 0: print('malicious_grads shape is ', malicious_grads.shape)\n",
    "\n",
    "        agg_grads, our_candidates = dnc(malicious_grads, n_attacker, num_buckets=num_buckets, bucket=bucket_size)\n",
    "        \n",
    "        if n_attacker:\n",
    "            if epoch_num > 0 and (epoch_num%50==0 or epoch_num == (nepochs-1)):\n",
    "                try:\n",
    "                    print('number of malicious grads chosen are ', np.array(candidates).reshape(5, 10))\n",
    "                except:\n",
    "                    print('number of malicious grads chosen are ', np.array(candidates))\n",
    "                candidates = []\n",
    "                candidates.append(np.sum(our_candidates < n_attacker))\n",
    "            else:\n",
    "                candidates.append(np.sum(our_candidates < n_attacker))\n",
    "\n",
    "        del user_grads\n",
    "\n",
    "        start_idx=0\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        save_checkpoint_global(\n",
    "            {\n",
    "                'epoch': epoch_num,\n",
    "                'state_dict': fed_model.state_dict(),\n",
    "                'best_global_acc': best_global_acc,\n",
    "                'best_global_te_acc': best_global_te_acc,\n",
    "                'optimizer': optimizer_fed.state_dict()\n",
    "            },\n",
    "            is_best,\n",
    "            checkpoint=chkpt,\n",
    "            filename=fed_file,\n",
    "            best_filename=fed_best_file,\n",
    "        )\n",
    "        \n",
    "        if epoch_num%10==0 or epoch_num==nepochs-1:\n",
    "            print('%s: at %s n_at %d z %.2f e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, n_attacker, z_values[n_attacker], epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        if val_loss > 10:\n",
    "            print('val loss %f too high'%val_loss)\n",
    "            break\n",
    "        \n",
    "        epoch_num+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
